#!/usr/bin/env python

"""Identify mutation updates.

Yhaplo relies on a specific freeze of the ISOGG tree and SNP dataset.
Occasionally, errors are found and corrected therein. This script assesses which
mutations used by Yhaplo are no longer concordant with the current ISOGG SNP dataset.
It then patches a Yhaplo input file whose purpose is to correct for these errors.

For example, Y4010 (also known as FGC5628) on the R1b1a2a1a2c1f2a1a branch used to be
listed as "A->C", but it has since been corrected to "C->A".
"""

import csv
import logging
import os

import pandas as pd

# Input
INPUT_DIR = "input"
CURRENT_ISOGG_FP = os.path.join(INPUT_DIR, "isogg.snp.index.2020.12.25.csv")
PREV_ISOGG_UNIQUE_FP = os.path.join(INPUT_DIR, "isogg.snps.unique.2016.01.04.txt")
MUTATION_CORRECTIONS_FP = os.path.join(INPUT_DIR, "isogg.correct.polarize.txt")

# Output
OUTPUT_DIR = "output"
OVERLAP_FP = os.path.join(OUTPUT_DIR, "overlap.txt")
PATCH_SNPS_FP = os.path.join(OUTPUT_DIR, "isogg.correct.polarize.patch.txt")
UPDATED_CORRECTIONS_FP = os.path.join(OUTPUT_DIR, "isogg.correct.polarize.updated.txt")

# Logging
LOG_FP = os.path.join(OUTPUT_DIR, "log.discordant.snps.txt")
logging.basicConfig(format="%(message)s", level=logging.INFO)
logger = logging.getLogger()

# Constants
COL_NAMES = ["name", "haplogroup", "position", "mutation", "alt_names"]


# ----------------------------------------------------------------------
class MutationUpdater:

    """Class for updating yhaplo's allele corrections file.

    Attributes
    ----------
    current_isogg_fp
        Filepath to current ISOGG SNP index
        Downloaded as CSV from:
        https://docs.google.com/spreadsheets/d/1UY26FvLE3UmEmYFiXgOy0uezJi_wOut-V5TD0a_6-bE
    prev_isogg_unique_fp
        Filepath to previous table of unique ISOGG SNPs.
        Generated by running `yhaplo` at the command line.
    mutation_corrections_fp
        Filepath of corrections yhaplo already knows about.
        From yhaplo's input directory:
        https://github.com/23andMe/yhaplo/blob/master/yhaplo/input/isogg.correct.polarize.txt
    patch_snps_fp
        Filepath to which discordant SNPs will be written.
    updated_corrections_fp
        Filepath to which updated corrections should be written.
    overlap_fp
        Filepath of overlap between extant file and putative patch.
    current_mutation_dict
        Maps SNP name to mutation (e.g., "G->A").
    patch_df
        DataFrame with updated mutations.
    original_df
        DataFrame with corrections yhaplo already knows about.
    dup_df
        DataFrame of overlap between patch_df and original_df.
    merged_df
        DataFrame with a reconciled and updated corrections table.

    """

    def __init__(
        self,
        current_isogg_fp: str = CURRENT_ISOGG_FP,
        prev_isogg_unique_fp: str = PREV_ISOGG_UNIQUE_FP,
        mutation_corrections_fp: str = MUTATION_CORRECTIONS_FP,
        patch_snps_fp: str = PATCH_SNPS_FP,
        updated_corrections_fp: str = UPDATED_CORRECTIONS_FP,
        overlap_fp: str = OVERLAP_FP,
    ):
        # Input
        self.current_isogg_fp = current_isogg_fp
        self.prev_isogg_unique_fp = prev_isogg_unique_fp
        self.mutation_corrections_fp = mutation_corrections_fp

        # Output
        self.patch_snps_fp = patch_snps_fp
        self.updated_corrections_fp = updated_corrections_fp
        self.overlap_fp = overlap_fp

    def run(self) -> None:
        """Run."""

        self.current_name_to_mutation = self._load_current_name_to_mutation()
        self.patch_df = self._construct_patch_df()
        self.original_df = self._load_previous_corrections()
        self.dup_df, self.merged_df = self._merge_corrections()

    def _load_current_name_to_mutation(self) -> dict[str, str]:
        """Read current ISOGG SNP index to define a mapping of SNP name to mutation.

        Returns
        -------
        name_to_mutation : dict[str, str]
            Maps SNP name to mutation.

        """
        name_to_mutation = {}
        num_read = 0
        with open(self.current_isogg_fp) as current_isogg_file:
            current_isogg_reader = csv.reader(current_isogg_file)
            for row_list in current_isogg_reader:
                num_read += 1
                name, mutation = row_list[0], row_list[-1]
                name_to_mutation[name] = mutation

        logger.info(f"{num_read:7d} current SNP records:  {self.current_isogg_fp}")

        return name_to_mutation

    def _construct_patch_df(self) -> pd.DataFrame:
        """Construct patch DataFrame.

        Read a previous table of unique ISOGG SNPs and report those whose mutations
        are discordant with the current ISOGG SNP index.

        Returns
        -------
        patch_df : pd.DataFrame
            Table of mutation patches.

        """
        num_used = 0
        row_lists = []
        with open(self.prev_isogg_unique_fp) as prev_isogg_unique_file:
            for line in prev_isogg_unique_file:
                num_used += 1
                row_list = line.strip().split()
                name, mutation = row_list[0], row_list[3]
                current_mutation = self.current_name_to_mutation.get(name)
                if current_mutation and current_mutation != mutation:
                    row_list[3] = current_mutation
                    row_lists.append(row_list)

        patch_df = pd.DataFrame(row_lists, columns=COL_NAMES).set_index("name")
        write_snp_table(patch_df, self.patch_snps_fp)
        logger.info(
            f"{num_used:7d} used by yhaplo:"
            f"       {self.prev_isogg_unique_fp}\n\n"
            f"{len(patch_df):7d} discordant mutations: {self.patch_snps_fp}"
        )

        return patch_df

    def _load_previous_corrections(self) -> pd.DataFrame:
        """Load previous corrections file.

        Returns
        -------
        original_df : pd.DataFrame
            Dataframe of original corrections.

        """
        original_df = pd.read_csv(
            self.mutation_corrections_fp,
            sep=r"\s+",
            header=None,
            names=COL_NAMES,
        ).set_index("name")
        logger.info(
            f"{len(original_df):7d} extant corrections:   "
            f"{self.mutation_corrections_fp}\n"
        )

        return original_df

    def _merge_corrections(self) -> tuple[pd.DataFrame, pd.DataFrame]:
        """Load known mutation corrections and merge with new corrections.

        In doing so, take care not to inappapropriately override.

        Returns
        -------
        dup_df : pd.DataFrame
            Duplicates.
        merged_df : pd.DataFrame
            Merged corrections.

        """
        # Investigate overlap
        suffixes = ("_orig", "_patch")
        dup_df = self.original_df.merge(
            self.patch_df,
            left_index=True,
            right_index=True,
            suffixes=suffixes,
        )
        for suffix in suffixes:
            alleles = dup_df["mutation" + suffix].str.split("->", expand=True)
            dup_df["anc" + suffix] = alleles[0]
            dup_df["der" + suffix] = alleles[1]

        with open(self.overlap_fp, "w") as overlap_file:
            overlap_file.write(dup_df.to_string() + "\n")

        logger.info(f"{len(dup_df):7d} overlap:              {self.overlap_fp}")

        # Handle overlap
        ancestral_consistent = dup_df["anc_orig"] == dup_df["anc_patch"]
        override_indexes = dup_df.loc[ancestral_consistent].index
        do_not_patch_indexes = dup_df.loc[~ancestral_consistent].index
        original_df = self.original_df.drop(override_indexes)
        patch_df = self.patch_df.drop(do_not_patch_indexes)
        logger.info(
            f"{len(override_indexes):7d} excluded from original "
            "(ancestral alleles consistent): "
            f"{', '.join(override_indexes)}"
        )
        logger.info(
            f"{len(do_not_patch_indexes):7d} excluded from patch: "
            f"{', '.join(do_not_patch_indexes)}\n"
        )

        # Merge
        merged_df = pd.concat([original_df, patch_df]).sort_values(
            ["haplogroup", "position"]
        )
        write_snp_table(merged_df, self.updated_corrections_fp)
        logger.info(
            f"{len(merged_df):7d} merged:               "
            f"{self.updated_corrections_fp}\n"
        )

        return dup_df, merged_df


def make_parent_dir(file_path: str) -> None:
    """Make parent directory."""

    dirname = os.path.dirname(file_path)
    if dirname:
        os.makedirs(dirname, exist_ok=True)


def write_snp_table(df: pd.DataFrame, out_fp: str) -> None:
    """Write a SNP table to file."""

    with open(out_fp, "w") as out_file:
        for name, row in df.iterrows():
            out_file.write(
                f"{name:15} {row.haplogroup:25} {row.position:>8} "
                f"{row.mutation}     {row.alt_names}\n"
            )


def main() -> None:
    """Run script."""

    make_parent_dir(LOG_FP)
    logger.addHandler(logging.FileHandler(LOG_FP, "w"))

    mutation_updater = MutationUpdater()
    mutation_updater.run()

    logger.info(f"Log: {LOG_FP}\n")


if __name__ == "__main__":
    main()
